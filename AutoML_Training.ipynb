{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UHXIXZWD8q0n"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import string\n",
        "import random\n",
        "# import firebase_admin\n",
        "# from firebase_admin import credentials\n",
        "# from firebase_admin import firestore\n",
        "# import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "73lSYjzI-LsZ"
      },
      "outputs": [],
      "source": [
        "demo_df = pd.read_csv(r\"Dummy Data HSS.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'C:\\sujan\\git learning\\git\\bigdata\\maximal-record-384001-406302dda581.json' \n",
        "def write_read(bucket_name, blob_name):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(blob_name)\n",
        "    blob.upload_from_filename('upload_imputed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gf30A0ccsoXa"
      },
      "outputs": [],
      "source": [
        "def impute(data):\n",
        "    #checking missing values\n",
        "    percent_missing = data.isnull().sum() * 100 / data.shape[0]\n",
        "    #dropping columns if missing percentage is more than 30\n",
        "    for i in range(len(data.columns)):\n",
        "        if percent_missing[i] >30:\n",
        "            data.drop(data.columns[i],axis=1,inplace=True)\n",
        "    #getting numerical and categorical variables\n",
        "    numerical_columns = [x for x in data.columns if data[x].dtype != 'object']\n",
        "    data_num = data[numerical_columns]\n",
        "    \n",
        "    cat_columns = [x for x in data.columns if x not in numerical_columns]\n",
        "    data_cat = data[cat_columns]\n",
        "    \n",
        "    #Imputing using KNN Imputer for numerical columns\n",
        "    imputer = KNNImputer(n_neighbors=2)\n",
        "    imputed_num = imputer.fit_transform(data_num)\n",
        "    imputed_num = pd.DataFrame(imputed_num)\n",
        "    imputed_num.columns=data_num.columns\n",
        "    \n",
        "    # most frequent imputation for categorical columns\n",
        "    data_cat_imputed = data_cat.apply(lambda x: x.fillna(x.value_counts().index[0]))\n",
        "    \n",
        "    #concat the imputed dfs\n",
        "    imputed_data = pd.concat([imputed_num, data_cat_imputed], axis=1)\n",
        "    imputed_data.to_csv('upload_imputed.csv',index = False)\n",
        "    write_read('automl-bigdata', 'remove.csv')\n",
        "    #return imputed_data\n",
        "    return imputed_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8nu5aEZSspik"
      },
      "outputs": [],
      "source": [
        "ll = impute(demo_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dNEQcU_gtEMt"
      },
      "outputs": [],
      "source": [
        "def normalize_and_encode(imputed_data):\n",
        "    #normalizing numerical columns using robustscalar\n",
        "    numerical_columns  = [x for x in imputed_data.columns if imputed_data[x].dtype in ['int64', 'float64']]\n",
        "    scalar = RobustScaler(quantile_range=(25,75))\n",
        "    scaled = scalar.fit_transform(imputed_data[numerical_columns])\n",
        "    scaled = pd.DataFrame(scaled)\n",
        "    scaled.columns = imputed_data[numerical_columns].columns\n",
        "    \n",
        "    #dropping cat columns with more than 10 categories\n",
        "    cat_cols = [x for x in imputed_data.columns if x not in numerical_columns]\n",
        "    cat_cols_to_drop = []\n",
        "    for col in cat_cols:\n",
        "        if imputed_data[col].value_counts().count()>10:\n",
        "            cat_cols_to_drop.append(col)\n",
        "    data_for_enc = imputed_data.drop(numerical_columns,axis=1)\n",
        "    data_for_enc.drop(cat_cols_to_drop,axis=1,inplace=True)\n",
        "\n",
        "    #encoding categorical varialbles\n",
        "    enc_data= pd.get_dummies(data_for_enc, columns=data_for_enc.columns)\n",
        "    \n",
        "    encoded_data = pd.concat([scaled, enc_data], axis=1)\n",
        "\n",
        "    return encoded_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JPk6JpBytHzU"
      },
      "outputs": [],
      "source": [
        "train = normalize_and_encode(ll)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qtxnpR4jwZJB"
      },
      "outputs": [],
      "source": [
        "reg_models = [\n",
        "    KNeighborsRegressor(),\n",
        "    GradientBoostingRegressor(),\n",
        "    ExtraTreesRegressor(),\n",
        "    RandomForestRegressor(),\n",
        "    DecisionTreeRegressor(),\n",
        "    LinearRegression(),\n",
        "    Lasso(),\n",
        "    Ridge()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N91P_QxAHDfX",
        "outputId": "8f67e9c7-cfb6-4272-c862-ba16b1501f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<google.cloud.firestore_v1.client.Client at 0x7f5c2175dd90>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from firebase_admin import firestore\n",
        "cred = credentials.Certificate('/content/auto-ml-af39c-firebase-adminsdk-37cmd-35f3911f5e.json')\n",
        "app = firebase_admin.initialize_app(cred)\n",
        "dummy = firestore.client()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "vbFeRRK_T9zU"
      },
      "outputs": [],
      "source": [
        "def connection():\n",
        "  cred = credentials.Certificate('/content/auto-ml-af39c-firebase-adminsdk-37cmd-35f3911f5e.json')\n",
        "  try:\n",
        "    app = firebase_admin.initialize_app(cred)\n",
        "  except:\n",
        "    app = firebase_admin.initialize_app(cred, name = str(random.random()))\n",
        "  return firestore.client()\n",
        "\n",
        "def training(train_data, y, reg_models):\n",
        "  db = connection()  \n",
        "  y_class = train_data[[y]]\n",
        "  \n",
        "  X_train, X_val, y_train, y_val = train_test_split(train_data.drop(y, axis=1), y_class, test_size=0.2, random_state=100)\n",
        "  \n",
        "  res = {}\n",
        "  \n",
        "  KNeighborsRegressor_grid = {\n",
        "      'n_neighbors':[2,5,10], \n",
        "      'weights': ['uniform', 'distance'], \n",
        "      'algorithm': ['auto','ball_tree','kd_tree','brute'],\n",
        "      'leaf_size': [15,30,45],\n",
        "      }\n",
        "\n",
        "  GradientBoostingRegressor_grid = {\n",
        "      'loss':['squared_error', 'absolute_error', 'huber', 'quantile'],\n",
        "      'learning_rate':[0.1,0.5,0.8],\n",
        "      'n_estimators':[10,50,100]\n",
        "  }\n",
        "\n",
        "  ExtraTreesRegressor_grid = {\n",
        "      'n_estimators':[10,50,100],\n",
        "      'criterion':['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
        "  }\n",
        "\n",
        "  RandomForestRegressor_grid = {\n",
        "      'n_estimators':[10,50,100],\n",
        "      'criterion':['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
        "  }\n",
        "\n",
        "  DecisionTreeRegressor_grid = {\n",
        "      'criterion':['squared_error', 'friedman_mse', 'absolute_error', 'poisson'],\n",
        "      'splitter':['best','random']\n",
        "  }\n",
        "\n",
        "  LinearRegression_grid = {\n",
        "    'fit_intercept': [True, False]\n",
        "  }\n",
        "\n",
        "  Lasso_grid = {\n",
        "      'alpha': [0.1, 0.2, 0.5],\n",
        "      'fit_intercept': [True, False]\n",
        "  }\n",
        "  Ridge_grid = {\n",
        "       'alpha': [0.1, 0.2, 0.5],\n",
        "      'fit_intercept': [True, False]\n",
        "  }\n",
        "  \n",
        " \n",
        "  params = { \n",
        "      'KNeighborsRegressor': KNeighborsRegressor_grid,\n",
        "      'GradientBoostingRegressor': GradientBoostingRegressor_grid,\n",
        "      'ExtraTreesRegressor': ExtraTreesRegressor_grid,\n",
        "      'RandomForestRegressor': RandomForestRegressor_grid,\n",
        "      'DecisionTreeRegressor': DecisionTreeRegressor_grid,\n",
        "      'LinearRegression': LinearRegression_grid, \n",
        "      'Lasso': Lasso_grid,\n",
        "      'Ridge':Ridge_grid\n",
        "    }\n",
        "\n",
        "  for reg in reg_models:\n",
        "    name = reg.__class__.__name__  \n",
        "    try:\n",
        "      clf = RandomizedSearchCV(reg, params[name], random_state=0)\n",
        "    except:\n",
        "      print(name)\n",
        "      continue\n",
        "    results = clf.fit(X_train, y_train)\n",
        "    print(results.best_params_)\n",
        "    r2 = round(r2_score(y_val, clf.predict(X_val)), 3)\n",
        "    rmse = round(mean_squared_error(y_val, clf.predict(X_val)), 3)\n",
        "    N = 16\n",
        " \n",
        "    string_name = ''.join(random.choices(string.ascii_uppercase + string.ascii_lowercase + string.digits, k = N))\n",
        "\n",
        "    while string_name in db.collection(u'models').stream():\n",
        "        string_name = ''.join(random.choices(string.ascii_uppercase + string.ascii_lowercase + string.digits, k = N))\n",
        "\n",
        "    print(\"{} trained with an RMSE of : {} and an accuracy of: {}\".format(name, rmse, r2))\n",
        "    \n",
        "    res[name] = {\n",
        "        'RMSE': rmse,\n",
        "         'r2': r2,\n",
        "         'params': results.best_params_\n",
        "      }  \n",
        "\n",
        "  # Add a new doc in collection 'cities' with ID 'LA'\n",
        "  db.collection(u'models').document(string_name).set(res)\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl66Q5ZAHx2k",
        "outputId": "d7c4bbc1-cbc4-4e27-a5cb-95ee7bc2d66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'weights': 'distance', 'n_neighbors': 5, 'leaf_size': 30, 'algorithm': 'ball_tree'}\n",
            "KNeighborsRegressor trained with an RMSE of : 0.003 and an accuracy of: 0.99\n",
            "{'n_estimators': 100, 'loss': 'squared_error', 'learning_rate': 0.1}\n",
            "GradientBoostingRegressor trained with an RMSE of : 0.0 and an accuracy of: 0.999\n",
            "{'n_estimators': 50, 'criterion': 'absolute_error'}\n",
            "ExtraTreesRegressor trained with an RMSE of : 0.0 and an accuracy of: 0.999\n",
            "{'n_estimators': 50, 'criterion': 'absolute_error'}\n",
            "RandomForestRegressor trained with an RMSE of : 0.0 and an accuracy of: 0.999\n",
            "{'splitter': 'random', 'criterion': 'absolute_error'}\n",
            "DecisionTreeRegressor trained with an RMSE of : 0.001 and an accuracy of: 0.998\n",
            "{'fit_intercept': True}\n",
            "LinearRegression trained with an RMSE of : 0.0 and an accuracy of: 0.999\n",
            "{'fit_intercept': False, 'alpha': 0.1}\n",
            "Lasso trained with an RMSE of : 0.029 and an accuracy of: 0.912\n",
            "{'fit_intercept': False, 'alpha': 0.1}\n",
            "Ridge trained with an RMSE of : 0.0 and an accuracy of: 0.999\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'KNeighborsRegressor': {'RMSE': 0.003,\n",
              "  'r2': 0.99,\n",
              "  'params': {'weights': 'distance',\n",
              "   'n_neighbors': 5,\n",
              "   'leaf_size': 30,\n",
              "   'algorithm': 'ball_tree'}},\n",
              " 'GradientBoostingRegressor': {'RMSE': 0.0,\n",
              "  'r2': 0.999,\n",
              "  'params': {'n_estimators': 100,\n",
              "   'loss': 'squared_error',\n",
              "   'learning_rate': 0.1}},\n",
              " 'ExtraTreesRegressor': {'RMSE': 0.0,\n",
              "  'r2': 0.999,\n",
              "  'params': {'n_estimators': 50, 'criterion': 'absolute_error'}},\n",
              " 'RandomForestRegressor': {'RMSE': 0.0,\n",
              "  'r2': 0.999,\n",
              "  'params': {'n_estimators': 50, 'criterion': 'absolute_error'}},\n",
              " 'DecisionTreeRegressor': {'RMSE': 0.001,\n",
              "  'r2': 0.998,\n",
              "  'params': {'splitter': 'random', 'criterion': 'absolute_error'}},\n",
              " 'LinearRegression': {'RMSE': 0.0,\n",
              "  'r2': 0.999,\n",
              "  'params': {'fit_intercept': True}},\n",
              " 'Lasso': {'RMSE': 0.029,\n",
              "  'r2': 0.912,\n",
              "  'params': {'fit_intercept': False, 'alpha': 0.1}},\n",
              " 'Ridge': {'RMSE': 0.0,\n",
              "  'r2': 0.999,\n",
              "  'params': {'fit_intercept': False, 'alpha': 0.1}}}"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training(train, 'Sales', reg_models=reg_models)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
